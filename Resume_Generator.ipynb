{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQb/FhRng5z6ZP7dBma67C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarthikeyanBaskaran/pdf-build/blob/main/Resume_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how can i pip install without output steps\n",
        "\n",
        "!pip install --quiet groq\n"
      ],
      "metadata": {
        "id": "6rCgqRLsZqUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "! apt-get install git"
      ],
      "metadata": {
        "id": "xKt6eA3dz5yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/KarthikeyanBaskaran/pdf-build.git"
      ],
      "metadata": {
        "id": "MDWKz0kvz8yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jd = \"\"\"\n",
        "StackAdapt is a self-serve advertising platform that specializes in multi-channel solutions including native, display, video, connected TV, audio, in-game, and digital out-of-home ads. We empower hundreds of digitally-focused companies to deliver outcomes and exceptional campaign performance everyday. StackAdapt was founded with a vision to be more than an advertising platform, it’s a hub of innovation, imagination and creativity.\n",
        "\n",
        "We're looking to add Data Engineers to our data science team! This team works on solving complex problems for StackAdapt's digital advertising platform. You'll be working directly with our data scientists, data engineers, Engineering team, and CTO on building pipelines and ad optimization models. With databases that process millions of requests per second, there's no shortage of data and problems to tackle.\n",
        "\n",
        "Want to learn more about our Data Science Team: https://alldus.com/ie/blog/podcasts/aiinaction-ned-dimitrov-stackadapt/\n",
        "\n",
        "Learn more about our team culture here: https://www.stackadapt.com/careers/data-science\n",
        "\n",
        "Watch our talk at Amazon Tech Talks: https://www.youtube.com/watch?v=lRqu-a4gPuU\n",
        "\n",
        "StackAdapt is a Remote First company, and we are open to candidates in various of our operating locations throughout the globe!\n",
        "\n",
        "What you'll be doing:\n",
        "\n",
        "Design modular and scalable real time data pipelines to handle huge datasets\n",
        "Understand and implement custom ML algorithms in a low latency environment\n",
        "Work on microservice architectures that run training, inference, and monitoring on thousands of ML models concurrently\n",
        "\n",
        "What you'll bring to the table:\n",
        "\n",
        "Have the ability to take an ambiguously defined task, and break it down into actionable steps\n",
        "Have deep understanding of algorithm and software design, concurrency, and data structures\n",
        "Experience in implementing probabilistic or machine learning algorithms\n",
        "Interest in designing scalable distributed systems\n",
        "A high GPA from a well-respected Computer Science program\n",
        "Enjoy working in a friendly, collaborative environment with others\n",
        "\n",
        "StackAdapters enjoy:\n",
        "\n",
        "Competitive salary + equity\n",
        "RRSP matching\n",
        "3 weeks vacation + 3 personal care days + 1 Culture & Belief day + birthdays off\n",
        "Access to a comprehensive mental health care platform\n",
        "Health benefits from day one of employment\n",
        "Work from home reimbursements\n",
        "Optional global WeWork membership for those who want a change from their home office\n",
        "Robust training and onboarding program\n",
        "Coverage and support of personal development initiatives (conferences, courses, etc)\n",
        "Access to StackAdapt programmatic courses and certifications to support continuous learning\n",
        "Mentorship opportunities with industry leaders\n",
        "An awesome parental leave policy\n",
        "A friendly, welcoming, and supportive culture\n",
        "Our social and team events!\n",
        "\n",
        "If this role speaks to you then please apply - we'd love to speak with you. Due to a high volume of interest, only those shortlisted for interview will be contacted.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FWmmCBGhQ3Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MyResume = \"\"\"Professional Experience:\n",
        "1. Procurement Engineer, Vestas Wind Technology, India (Nov 2021 – Aug 2023):\n",
        "•\tAchieved a 15% reduction in procurement costs by developing a data-driven supplier evaluation model and conducting detailed cost analysis.\n",
        "•\tImproved project timelines by 20% through predictive analytics for demand forecasting and proactive delay management.\n",
        "•\tSaved $85M annually by developing and implementing Python-based automation tools, streamlining procurement workflows and enhancing operational efficiency.\n",
        "•\tEnhanced supplier performance monitoring by designing vendor scorecards using Excel and Power BI, enabling data visualization for better decision-making.\n",
        "•\tIntegrated IT systems into procurement processes, deploying Microsoft Power Query and SharePoint to automate reporting and improve data accuracy, reducing manual efforts by 30%.\n",
        "•\tDeveloped a procurement dashboard in Power BI to track KPIs, supplier performance, and category spend, enabling leadership to make informed decisions.\n",
        "•\tOptimized material master data accuracy through automation, improving data consistency and reducing errors by 25%.\n",
        "•\tCollaborated with IT and cross-functional teams to develop scalable software solutions for supply chain monitoring, ensuring seamless integration with existing systems.\n",
        "•\tImplemented risk mitigation strategies by analyzing supply chain data and identifying alternative sourcing options to address potential delivery bottlenecks.\n",
        "•\tStreamlined RFQ processes using advanced quote comparison tools and automation, reducing processing time by 40%.\n",
        "•\tNegotiated supplier contracts to achieve cost savings and ensure compliance with government policies, leveraging IT tools for real-time data tracking.\n",
        "•\tDesigned and deployed customized procurement strategies to handle delivery complexities, ensuring continuity in production and minimizing downtime.\n",
        "•\tImproved KPI tracking by automating SLA adherence reporting, increasing visibility for stakeholders and reducing manual intervention.\n",
        "•\tLed IT-driven innovations in procurement by identifying opportunities for automation and implementing solutions that enhanced scalability and flexibility across procurement functions.\n",
        "\n",
        "2. Consultant ECM Purchaser, Vestas, ManpowerGroup Services, India (Jan 2021 – Nov 2021):\n",
        "•\tReduced production costs by 10% through process optimization analyses, utilizing data-driven insights to streamline operations.\n",
        "•\tIdentified potential savings of €3M by analyzing supplier costs and payment credit periods, implementing standardized and efficient procurement strategies.\n",
        "•\tImproved operational efficiency by 15% by leading cross-functional collaboration and deploying Lean methodologies.\n",
        "•\tEnhanced project delivery capacity by 20% through process improvements that freed up resources for handling additional projects.\n",
        "•\tDeveloped and deployed cloud-based automation tools, resulting in a 30% increase in team productivity and faster completion of routine tasks.\n",
        "•\tLed RFx processes across wind turbine segments, negotiating competitive pricing with global vendors and achieving an 8% reduction in procurement costs.\n",
        "•\tCollaborated with product management and design teams to define project scope and requirements, ensuring alignment with customer needs and delivering projects 10% faster.\n",
        "•\tBuilt Python-based automation scripts, optimizing internal workflows and reducing manual effort by 25%, enhancing team efficiency.\n",
        "•\tStrengthened stakeholder relationships by implementing efficient communication strategies, improving supplier and sponsor engagement by 12%.\n",
        "•\tDeveloped dashboards and reporting tools using Python and cloud services to monitor KPIs, improving decision-making accuracy by 18%.\n",
        "\n",
        "3. Procurement Engineer, Valeo India, India (Jun 2018 – Jan 2021):\n",
        "•\tManaged RFx processes across global wind turbine segments, achieving 10-15% cost reductions through competitive vendor sourcing and procurement strategies.\n",
        "•\tBuilt and maintained a robust supplier base by inducting vendors, implementing double sourcing, and driving localization, resulting in a 20% improvement in supply chain efficiency.\n",
        "•\tExecuted supplier auctions using digital platforms, reducing overall part costs by 8-12% while ensuring competitive pricing.\n",
        "•\tPerformed zero-based costing using advanced Excel (macros, pivot tables) and analytical tools, enabling 15% cost savings through data-driven negotiations.\n",
        "•\tDeveloped Power BI dashboards to track procurement KPIs, cutting reporting time by 40% and enhancing supplier performance monitoring.\n",
        "•\tUtilized Python and SQL to analyze procurement data, uncovering opportunities for cost optimization worth $500K+ annually.\n",
        "•\tIntegrated ERP tools (SAP) to streamline procurement workflows, reducing manual effort by 30% and enhancing process accuracy.\n",
        "•\tSourced globally from cost-effective suppliers to meet production demands, ensuring 100% on-time delivery and adherence to quality standards.\n",
        "•\tGained expertise in manufacturing techniques, achieving a 10% reduction in project costs by aligning processes with best-cost practices.\n",
        "•\tCollaborated on ERP system enhancements, reducing procurement cycle times by 20% and improving data accessibility for stakeholders.\n",
        "\n",
        "\n",
        "Education:\n",
        " Diploma in Data Analytics for Business, St. Clair College (2024):\n",
        " GPA: 4.0\n",
        "    Relevant coursework: Data Mining, Predictive Analytics, Database Management, and Machine Learning.\n",
        "\n",
        " Bachelor of Engineering, Mechanical,  St. Joseph’s institute of Technology (2024):\n",
        "   GPA: 3.5\n",
        "\n",
        "Certifications:\n",
        " SQL for Data Science (Coursera)\n",
        " Python for Data Analysis (Udemy)\n",
        " Tableau Desktop Specialist Certification\n",
        "\n",
        "#### Projects:\n",
        "1. Meta Financial Dashboard\n",
        "•\tDeveloped an interactive Tableau dashboard to analyze key financial KPIs such as P/E Ratio, Current Ratio, and Debt to Equity.\n",
        "•\tDelivered actionable insights that improved financial decisionmaking, enhancing reporting accuracy and strategic planning.\n",
        "2. Customer Churn Analysis\n",
        "•\tDesigned and implemented an ETL pipeline in Python to clean and process large ecommerce customer datasets.\n",
        "•\tPerformed predictive analytics to identify highrisk churn customers, leading to targeted retention strategies and a measurable reduction in churn rates.\n",
        "3. Vestas Process Automation\n",
        "•\tAutomated employee data collection, analysis, and visualization processes using Power BI, Python, and Excel.\n",
        "•\tLeveraged Microsoft Power Query for streamlined internal data gathering, improving traceability and key metric visibility, significantly benefiting senior management decisionmaking.\n",
        "4.  SAP Data Automation\n",
        "•\tDeveloped automation solutions to streamline data management between Excel and SAP systems using Excel VBA and SAP automation features.\n",
        "•\tEnabled seamless updates of Excel data into SAP, enhancing operational efficiency and data accuracy across departments.\n",
        "5. Plastic Pollution Overview Dashboard\n",
        "•\tCreated a dynamic Tableau dashboard to visualize global plastic pollution metrics, including waste generation, recycling rates, and environmental impacts.\n",
        "•\tIntegrated multiple data sources and provided filters for regional and temporal analysis, offering actionable insights for stakeholders and supporting sustainability efforts.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "i3Ya1muycJh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2M477ZGcv_h"
      },
      "outputs": [],
      "source": [
        "# Desired Skill\n",
        "\n",
        "from groq import Groq\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# Set up the client\n",
        "client = Groq(\n",
        "    api_key=userdata.get('GROQ_API_KEY')\n",
        ")\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles and other type of analyst roles\\n\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Step1: Extract all the keywords in the Job description which we need to use in resume. {jd} Step2: using the keyword extracted above and my resume  combine to generate an ideal resume for the job application.\n",
        "\n",
        "            Resume format:\n",
        "\n",
        "            *Work experience*\n",
        "            Company name\n",
        "            best suited 3 points with keywords\n",
        "\n",
        "            *Projects*\n",
        "            you can generate new projects with difficulty level easy when some mandatory keywords or technology is missing in my work experience\n",
        "            Title\n",
        "            short idea\n",
        "\n",
        "            {MyResume}\n",
        "            \"\"\"}\n",
        "\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "# Initialize a variable to store the output\n",
        "DesiredSkill = \"\"\n",
        "\n",
        "# Collect the response from the stream and store it\n",
        "for chunk in completion:\n",
        "    # Extract the content from the streamed chunk\n",
        "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
        "    DesiredSkill += content  # Append to the variable\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z00gWu9i0VQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq()\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{DesiredSkill}\\n\\n\\nPlease generate the updated resume sections in YAML format using the same structure as provided below. Make sure the output is valid YAML without any markdown formatting (i.e., no triple backticks) so it can be directly loaded by a YAML parser.\\n\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"workExperience:\\n  - title: Procurement Engineer\\n    company: Vestas Wind Technology, India\\n    dates: Nov 2021 - Aug 2023\\n    achievements:\\n      - Designed and implemented data-driven supplier evaluation models using Python, reducing procurement costs by 15% and improving predictive analytics for demand forecasting.\\n      - Developed and deployed automation tools using Python, streamlining procurement workflows and enhancing operational efficiency, resulting in $85M annual savings.\\n      - Collaborated with IT and cross-functional teams to develop scalable software solutions for supply chain monitoring, ensuring seamless integration with existing systems.\\n  - title: Consultant ECM Purchaser\\n    company: Vestas, ManpowerGroup Services, India\\n    dates: Jan 2021 - Nov 2021\\n    achievements:\\n      - Analyzed supplier costs and payment credit periods using data-driven insights, identifying potential savings of €3M and implementing standardized procurement strategies.\\n      - Developed and deployed cloud-based automation tools, resulting in a 30% increase in team productivity and faster completion of routine tasks.\\n      - Led RFx processes across wind turbine segments, negotiating competitive pricing with global vendors and achieving an 8% reduction in procurement costs.\\n  - title: Procurement Engineer\\n    company: Valeo India, India\\n    dates: Jun 2018 - Jan 2021\\n    achievements:\\n      - Managed RFx processes across global wind turbine segments, achieving 10-15% cost reductions through competitive vendor sourcing and procurement strategies.\\n      - Developed Power BI dashboards to track procurement KPIs, cutting reporting time by 40% and enhancing supplier performance monitoring.\\n      - Utilized Python and SQL to analyze procurement data, uncovering opportunities for cost optimization worth $500K+ annually.\\n\\nprojects:\\n  - title: Real-Time Data Pipeline for Advertising Analytics\\n    description: Designed and implemented a real-time data pipeline using Apache Kafka, Apache Storm, and Apache Cassandra to handle huge datasets and provide low-latency analytics for advertising campaigns.\\n    achievements:\\n      - Developed a microservice architecture to run training, inference, and monitoring on thousands of machine learning models concurrently.\\n  - title: Scalable Distributed System for Data Processing\\n    description: Built a scalable distributed system using Apache Hadoop, Apache Spark, and Apache Flink to process large datasets and provide actionable insights for business decision-making.\\n    achievements:\\n      - Implemented data structures and algorithms to optimize data processing and reduce latency.\\n  - title: Machine Learning Model for Predictive Analytics\\n    description: Developed a machine learning model using Python, scikit-learn, and TensorFlow to predict customer churn and provide targeted retention strategies.\\n    achievements:\\n      - Deployed the model in a cloud-based environment and integrated it with a data visualization dashboard to provide real-time insights.\\n  - title: Data Visualization Dashboard for Advertising Metrics\\n    description: Created a data visualization dashboard using Tableau to track key advertising metrics such as click-through rates, conversion rates, and return on investment.\\n    achievements:\\n      - Integrated multiple data sources and provided filters for regional and temporal analysis, offering actionable insights for stakeholders.\\n  - title: Cloud-Based Automation Solution for Data Management\\n    description: Developed a cloud-based automation solution using AWS Lambda, AWS Glue, and AWS S3 to streamline data management between different systems and provide real-time insights.\\n    achievements:\\n      - Implemented data structures and algorithms to optimize data processing and reduce latency.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_completion_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "# Initialize a variable to store the output\n",
        "yaml = \"\"\n",
        "\n",
        "# Collect the response from the stream and store it\n",
        "for chunk in completion:\n",
        "    # Extract the content from the streamed chunk\n",
        "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
        "    yaml += content  # Append to the variable\n"
      ],
      "metadata": {
        "id": "z5F7_7t5zvXr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}