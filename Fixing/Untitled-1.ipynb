{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0f45d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.14.1)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.6.15)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Downloading transformers-4.53.1-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.1/35.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "\u001b[31mERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\n",
      "    unknown package:\n",
      "        Expected sha256 30ac3869f6db17d170e0e556dd6cc5eee02647abc31ca856634d5a40f82c15b2\n",
      "             Got        e3ae54fbcddb44c12a858aa530ce50c566985510129c5ef18e31369ddeb8403a\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb3207b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hf_xet\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Installing collected packages: hf_xet\n",
      "Successfully installed hf_xet-1.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a99d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b971b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight and good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eec72ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description  = \"\"\"About the job\n",
    "About Versapay 🚀\n",
    "\n",
    "For growing businesses that need to accomplish more with less, Versapay’s Accounts Receivable Efficiency Suite simplifies the invoice-to-cash process by automating invoicing, facilitating B2B payments, and streamlining cash application with AI. Versapay integrates natively with top ERPs, while allowing businesses to collect with a self-serve payment portal and collaborate with customers and teammates to resolve what automation alone can’t. Owned by Great Hill Partners, Versapay’s employee base spans the U.S. and Canada with offices in Atlanta and Miami. With 10,000 customers and 5M+ companies transacting, Versapay facilitates 110M+ transactions and $170B+ in payments volume annually\n",
    "\n",
    "Think you might be the next Veep to join? Read on!!\n",
    "\n",
    "How you’ll make a huge impact here – and on your career: \n",
    "\n",
    "This role is all about getting hands-on in designing & coding scalable and highly performant software with a smart, collaborative team. Reporting to our VP of Engineering, Chief Architect, you will participate in innovation research tracks like AI/ML, as well as developing our unified/enterprise product architecture including emphasis on cloud scale performance & scalability roadmap enhancements. You’ll also play a part in pairing, coaching, and mentoring fellow VEEPs (Versapay’s Empowered and Enabled People).\n",
    "\n",
    "We’re interested to hear from individuals who are excited by designing and implementing modern cloud scale architecture/infrastructure processing hundreds of millions of transactions and billions in payment volumes.\n",
    "\n",
    "What You'll Do\n",
    "\n",
    "Drive us forward: Design, develop, and test, product features satisfying business & technical requirements on time and on budget. \n",
    "Develop the big picture: Define & maintain architecture principles, patterns, and standards with particular attention to scalable, and high performing design. \n",
    "Get in the weeds: Triage and correct performance and/or data integrity concerns by reviewing & evaluating code, data patches, system logs, and process/memory/disk consumption utilization. \n",
    "Collaborate across teams: Partner with product managers/analysts, customer care, DevOps, and other engineers on features and support cases, supporting technical decision making, and leading work that affects more and more complex systems and critical areas of our application. \n",
    "Lead research: Provide critical R&D to help us continue to design for scale and reliability as we grow (and we’re growing). \n",
    "Coach and mentor: Provide guidance to junior-intermediate engineers on the team and others when possible. \n",
    "\n",
    "What You'll Bring To The Team\n",
    "\n",
    "Practical experience: Background in computer science engineering and at least 7 years in software engineering under your belt, having written enterprise scale software in an agile test-driven culture that has shipped to market. Experience specifically in Ruby/Rails/Sinatra is a big plus. Proven machine learning integration using traditional techniques and/or AutoML platforms. \n",
    "Deep expertise: Strong knowledge & practice in a variety of technology spanning, algorithms/data-structures, languages (e.g. Ruby, Java, Python, C#), databases (e.g. Postgres, Oracle, SQLServer), operating systems (e.g. Mac, Windows, *nix), and benchmarking tools/techniques. Demonstrated experience leveraging LLMs and LLM cloud providers (e.g. Azure OpenAI, AWS Bedrock) for productivity and product benefit. \n",
    "Communication: Able to effectively deliver written and verbal communications that are clear, compelling, to socialize ideas and get buy-in. \n",
    "Follow-through/execution: Excellent organizational skills, work ethic, and passion to deliver on commitments. \n",
    "Proactiveness and curiosity: Able to work effectively in a team with minimal supervision, using your knowledge to source and resolve problems. \n",
    "Related industry knowledge: Preferably, experience in the Payments Industry and/or PCI/DSS, would be a strong asset. \n",
    "\n",
    "$180,000 - $200,000 a year\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28b8d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vestas_bullets = [\"Achieved a 15% reduction in procurement costs by developing a data-driven supplier evaluation and conducting detailed cost analysis.\",\n",
    "\"Accelerated project timelines by 20% by implementing predictive analytics for demand forecasting enhancing project delivery capacity.\",\n",
    "\"Delivered savings of $35M by developing and deploying Python-based automation tools that streamlined procurement workflows and enhanced operational efficiency.\",\n",
    "\"Elevated supplier performance monitoring through the implementation of vendor scorecards using Excel and Power BI, providing actionable data visualizations for improved decision-making.\",\n",
    "\"Integrated internal systems and procurement processes, leveraging Microsoft Power Query and SharePoint to automate operations and improve data accuracy, leading to a 30% reduction in manual efforts.\",\n",
    "\"Developed a comprehensive Power BI procurement dashboard to track KPIs, supplier performance, and category spend, empowering leadership with informed decision-making capabilities.\",\n",
    "\"Optimized material master data accuracy through VBA automation and SAP, improving data consistency and reducing errors by 25%.\",\n",
    "\"Collaborated with cross-functional teams to develop scalable software solutions for supply chain monitoring, ensuring seamless integration with existing systems.\",\n",
    "\"Mitigated supply chain risks by analyzing data and identifying alternative sourcing options, addressing potential delivery bottlenecks.\",\n",
    "\"Streamlined RFQ processes using advanced quote comparison tools and automation, cutting processing time by 40%.\",\n",
    "\"Negotiated supplier contracts to achieve significant cost savings and ensure compliance with government policies.\",\n",
    "\"Improved KPI tracking by automating SLA adherence reporting, increasing stakeholder transparency and reducing manual intervention\",\n",
    "\"Identifying opportunities for process automation and implementing solutions that enhanced scalability and flexibility across procurement functions.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "005523e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "yaml_file_path = '/home/madhushree/Documents/pdf-build/Fixing/Resume.yaml'\n",
    "with open(yaml_file_path, 'r') as f:\n",
    "    resume_data = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c695f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Achieved a 15% reduction in procurement costs by developing a data-driven supplier evaluation and conducting detailed cost analysis.',\n",
       " 'Accelerated project timelines by 20% by implementing predictive analytics for demand forecasting enhancing project delivery capacity.',\n",
       " 'Delivered savings of $35M by developing and deploying Python-based automation tools that streamlined procurement workflows and enhanced operational efficiency.',\n",
       " 'Elevated supplier performance monitoring through the implementation of vendor scorecards using Excel and Power BI, providing actionable data visualizations for improved decision-making.',\n",
       " 'Integrated internal systems and procurement processes, leveraging Microsoft Power Query and SharePoint to automate operations and improve data accuracy, leading to a 30% reduction in manual efforts.',\n",
       " 'Developed a comprehensive Power BI procurement dashboard to track KPIs, supplier performance, and category spend, empowering leadership with informed decision-making capabilities.',\n",
       " 'Optimized material master data accuracy through VBA automation and SAP, improving data consistency and reducing errors by 25%.',\n",
       " 'Collaborated with cross-functional teams to develop scalable software solutions for supply chain monitoring, ensuring seamless integration with existing systems.',\n",
       " 'Mitigated supply chain risks by analyzing data and identifying alternative sourcing options, addressing potential delivery bottlenecks.',\n",
       " 'Streamlined RFQ processes using advanced quote comparison tools and automation, cutting processing time by 40%.',\n",
       " 'Negotiated supplier contracts to achieve significant cost savings and ensure compliance with government policies.',\n",
       " 'Improved KPI tracking by automating SLA adherence reporting, increasing stakeholder transparency and reducing manual intervention.',\n",
       " 'Identifying opportunities for process automation and implementing solutions that enhanced scalability and flexibility across procurement functions.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_data['Professional Experience']['Vestas Wind Technology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa952da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ats_bullets = [\n",
    "    \"Reduced procurement costs by 15% ($2.1M annually) by implementing a supplier performance evaluation model and conducting granular cost breakdown analysis across 80+ vendors.\",\n",
    "    \"Accelerated project timelines by 20% by deploying predictive analytics models for demand forecasting, improving supply planning accuracy for over 120 SKUs.\",\n",
    "    \"Delivered $35M in cumulative savings over 2 years by building Python-based automation tools that streamlined PR/PO workflows, cut processing time by 50%, and reduced manual rework.\",\n",
    "    \"Enhanced supplier accountability by creating Excel- and Power BI-based vendor scorecards, improving performance tracking for 100+ vendors and reducing non-compliance incidents by 35%.\",\n",
    "    \"Achieved a 30% reduction in manual operations by automating procurement data pipelines using Microsoft Power Query and SharePoint, increasing reporting speed and data accuracy.\",\n",
    "    \"Developed an interactive Power BI dashboard monitoring 15+ procurement KPIs, supplier performance, and $50M+ in annual spend, supporting faster and data-backed decision-making by leadership.\",\n",
    "    \"Improved material master data accuracy by 25% by automating SAP entries with VBA scripts, minimizing manual input errors across 10K+ records.\",\n",
    "    \"Engineered cross-functional software solutions for supply chain monitoring and reporting, reducing status update turnaround time by 60% and increasing stakeholder visibility.\",\n",
    "    \"Reduced supply chain risk by 40% by identifying alternative sourcing options and building a mitigation matrix to handle vendor delays, improving OTIF (On Time In Full) metrics.\",\n",
    "    \"Shortened RFQ cycle time by 40% (from 5 days to 3 days) by automating quote comparison logic and standardizing supplier templates.\",\n",
    "    \"Negotiated supplier contracts that led to $1.8M in cost savings while ensuring adherence to legal and compliance frameworks.\",\n",
    "    \"Automated SLA tracking and reporting using Power BI and Excel macros, improving KPI visibility and reducing manual tracking time by 70%.\",\n",
    "    \"Led 7+ automation initiatives that increased process efficiency across procurement functions, enhancing scalability and reducing operational workload by ~25%.\",\n",
    "    \"Deployed machine learning models \"\n",
    "]\n",
    "\n",
    "vestas_bullets = ats_bullets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca463ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert job description and bullets to embeddings\n",
    "jd_embedding = model.encode(job_description, convert_to_tensor=True)\n",
    "bullet_embeddings = model.encode(vestas_bullets, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "afdc14f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity scores\n",
    "similarities = util.pytorch_cos_sim(jd_embedding, bullet_embeddings)[0].cpu().numpy()\n",
    "\n",
    "# Pair scores with bullets\n",
    "scored_bullets = list(zip(similarities, vestas_bullets))\n",
    "\n",
    "# Sort by similarity (descending)\n",
    "sorted_bullets = sorted(scored_bullets, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Top 3 most relevant bullets\n",
    "top_bullets = [b for _, b in sorted_bullets[:3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a9628e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4303562,\n",
       "  'Delivered $35M in cumulative savings over 2 years by building Python-based automation tools that streamlined PR/PO workflows, cut processing time by 50%, and reduced manual rework.'),\n",
       " (0.3804925,\n",
       "  'Developed an interactive Power BI dashboard monitoring 15+ procurement KPIs, supplier performance, and $50M+ in annual spend, supporting faster and data-backed decision-making by leadership.'),\n",
       " (0.37511218,\n",
       "  'Enhanced supplier accountability by creating Excel- and Power BI-based vendor scorecards, improving performance tracking for 100+ vendors and reducing non-compliance incidents by 35%.'),\n",
       " (0.3579539,\n",
       "  'Led 7+ automation initiatives that increased process efficiency across procurement functions, enhancing scalability and reducing operational workload by ~25%.'),\n",
       " (0.31845355,\n",
       "  'Engineered cross-functional software solutions for supply chain monitoring and reporting, reducing status update turnaround time by 60% and increasing stakeholder visibility.'),\n",
       " (0.30250335,\n",
       "  'Negotiated supplier contracts that led to $1.8M in cost savings while ensuring adherence to legal and compliance frameworks.'),\n",
       " (0.29868475,\n",
       "  'Accelerated project timelines by 20% by deploying predictive analytics models for demand forecasting, improving supply planning accuracy for over 120 SKUs.'),\n",
       " (0.28434548,\n",
       "  'Achieved a 30% reduction in manual operations by automating procurement data pipelines using Microsoft Power Query and SharePoint, increasing reporting speed and data accuracy.'),\n",
       " (0.2830409,\n",
       "  'Reduced supply chain risk by 40% by identifying alternative sourcing options and building a mitigation matrix to handle vendor delays, improving OTIF (On Time In Full) metrics.'),\n",
       " (0.26791114,\n",
       "  'Reduced procurement costs by 15% ($2.1M annually) by implementing a supplier performance evaluation model and conducting granular cost breakdown analysis across 80+ vendors.'),\n",
       " (0.23017876,\n",
       "  'Improved material master data accuracy by 25% by automating SAP entries with VBA scripts, minimizing manual input errors across 10K+ records.'),\n",
       " (0.22413245,\n",
       "  'Automated SLA tracking and reporting using Power BI and Excel macros, improving KPI visibility and reducing manual tracking time by 70%.'),\n",
       " (0.182711,\n",
       "  'Shortened RFQ cycle time by 40% (from 5 days to 3 days) by automating quote comparison logic and standardizing supplier templates.'),\n",
       " (0.15294902, 'Deployed machine learning models ML')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_bullets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0cdae52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delivered $35M in cumulative savings over 2 years by building Python-based automation tools that streamlined PR/PO workflows, cut processing time by 50%, and reduced manual rework.',\n",
       " 'Developed an interactive Power BI dashboard monitoring 15+ procurement KPIs, supplier performance, and $50M+ in annual spend, supporting faster and data-backed decision-making by leadership.',\n",
       " 'Enhanced supplier accountability by creating Excel- and Power BI-based vendor scorecards, improving performance tracking for 100+ vendors and reducing non-compliance incidents by 35%.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_bullets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5a16b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
