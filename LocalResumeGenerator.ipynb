{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "6rCgqRLsZqUs"
      },
      "outputs": [],
      "source": [
        "# # prompt: how can i pip install without output steps\n",
        "\n",
        "# !pip install --quiet groq pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "jd = input('Enter the job description here')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "i3Ya1muycJh3"
      },
      "outputs": [],
      "source": [
        "MyResume = \"\"\"Professional Experience:\n",
        "1. Procurement Engineer, Vestas Wind Technology, India (Nov 2021 – Aug 2023):\n",
        "•\tAchieved a 15% reduction in procurement costs by developing a data-driven supplier evaluation model and conducting detailed cost analysis.\n",
        "•\tImproved project timelines by 20% through predictive analytics for demand forecasting and proactive delay management.\n",
        "•\tSaved $85M annually by developing and implementing Python-based automation tools, streamlining procurement workflows and enhancing operational efficiency.\n",
        "•\tEnhanced supplier performance monitoring by designing vendor scorecards using Excel and Power BI, enabling data visualization for better decision-making.\n",
        "•\tIntegrated IT systems into procurement processes, deploying Microsoft Power Query and SharePoint to automate reporting and improve data accuracy, reducing manual efforts by 30%.\n",
        "•\tDeveloped a procurement dashboard in Power BI to track KPIs, supplier performance, and category spend, enabling leadership to make informed decisions.\n",
        "•\tOptimized material master data accuracy through automation, improving data consistency and reducing errors by 25%.\n",
        "•\tCollaborated with IT and cross-functional teams to develop scalable software solutions for supply chain monitoring, ensuring seamless integration with existing systems.\n",
        "•\tImplemented risk mitigation strategies by analyzing supply chain data and identifying alternative sourcing options to address potential delivery bottlenecks.\n",
        "•\tStreamlined RFQ processes using advanced quote comparison tools and automation, reducing processing time by 40%.\n",
        "•\tNegotiated supplier contracts to achieve cost savings and ensure compliance with government policies, leveraging IT tools for real-time data tracking.\n",
        "•\tDesigned and deployed customized procurement strategies to handle delivery complexities, ensuring continuity in production and minimizing downtime.\n",
        "•\tImproved KPI tracking by automating SLA adherence reporting, increasing visibility for stakeholders and reducing manual intervention.\n",
        "•\tLed IT-driven innovations in procurement by identifying opportunities for automation and implementing solutions that enhanced scalability and flexibility across procurement functions.\n",
        "\n",
        "2. Consultant ECM Purchaser, Vestas, ManpowerGroup Services, India (Jan 2021 – Nov 2021):\n",
        "•\tReduced production costs by 10% through process optimization analyses, utilizing data-driven insights to streamline operations.\n",
        "•\tIdentified potential savings of €3M by analyzing supplier costs and payment credit periods, implementing standardized and efficient procurement strategies.\n",
        "•\tImproved operational efficiency by 15% by leading cross-functional collaboration and deploying Lean methodologies.\n",
        "•\tEnhanced project delivery capacity by 20% through process improvements that freed up resources for handling additional projects.\n",
        "•\tDeveloped and deployed cloud-based automation tools, resulting in a 30% increase in team productivity and faster completion of routine tasks.\n",
        "•\tLed RFx processes across wind turbine segments, negotiating competitive pricing with global vendors and achieving an 8% reduction in procurement costs.\n",
        "•\tCollaborated with product management and design teams to define project scope and requirements, ensuring alignment with customer needs and delivering projects 10% faster.\n",
        "•\tBuilt Python-based automation scripts, optimizing internal workflows and reducing manual effort by 25%, enhancing team efficiency.\n",
        "•\tStrengthened stakeholder relationships by implementing efficient communication strategies, improving supplier and sponsor engagement by 12%.\n",
        "•\tDeveloped dashboards and reporting tools using Python and cloud services to monitor KPIs, improving decision-making accuracy by 18%.\n",
        "\n",
        "3. Procurement Engineer, Valeo India, India (Jun 2018 – Jan 2021):\n",
        "•\tManaged RFx processes across global wind turbine segments, achieving 10-15% cost reductions through competitive vendor sourcing and procurement strategies.\n",
        "•\tBuilt and maintained a robust supplier base by inducting vendors, implementing double sourcing, and driving localization, resulting in a 20% improvement in supply chain efficiency.\n",
        "•\tExecuted supplier auctions using digital platforms, reducing overall part costs by 8-12% while ensuring competitive pricing.\n",
        "•\tPerformed zero-based costing using advanced Excel (macros, pivot tables) and analytical tools, enabling 15% cost savings through data-driven negotiations.\n",
        "•\tDeveloped Power BI dashboards to track procurement KPIs, cutting reporting time by 40% and enhancing supplier performance monitoring.\n",
        "•\tUtilized Python and SQL to analyze procurement data, uncovering opportunities for cost optimization worth $500K+ annually.\n",
        "•\tIntegrated ERP tools (SAP) to streamline procurement workflows, reducing manual effort by 30% and enhancing process accuracy.\n",
        "•\tSourced globally from cost-effective suppliers to meet production demands, ensuring 100% on-time delivery and adherence to quality standards.\n",
        "•\tGained expertise in manufacturing techniques, achieving a 10% reduction in project costs by aligning processes with best-cost practices.\n",
        "•\tCollaborated on ERP system enhancements, reducing procurement cycle times by 20% and improving data accessibility for stakeholders.\n",
        "\n",
        "\n",
        "Education:\n",
        " Diploma in Data Analytics for Business, St. Clair College (2024):\n",
        " GPA: 4.0\n",
        "    Relevant coursework: Data Mining, Predictive Analytics, Database Management, and Machine Learning.\n",
        "\n",
        " Bachelor of Engineering, Mechanical,  St. Joseph’s institute of Technology (2024):\n",
        "   GPA: 3.5\n",
        "\n",
        "Certifications:\n",
        " SQL for Data Science (Coursera)\n",
        " Python for Data Analysis (Udemy)\n",
        " Tableau Desktop Specialist Certification\n",
        "\n",
        "#### Projects:\n",
        "1. Meta Financial Dashboard\n",
        "•\tDeveloped an interactive Tableau dashboard to analyze key financial KPIs such as P/E Ratio, Current Ratio, and Debt to Equity.\n",
        "•\tDelivered actionable insights that improved financial decisionmaking, enhancing reporting accuracy and strategic planning.\n",
        "2. Customer Churn Analysis\n",
        "•\tDesigned and implemented an ETL pipeline in Python to clean and process large ecommerce customer datasets.\n",
        "•\tPerformed predictive analytics to identify highrisk churn customers, leading to targeted retention strategies and a measurable reduction in churn rates.\n",
        "3. Vestas Process Automation\n",
        "•\tAutomated employee data collection, analysis, and visualization processes using Power BI, Python, and Excel.\n",
        "•\tLeveraged Microsoft Power Query for streamlined internal data gathering, improving traceability and key metric visibility, significantly benefiting senior management decisionmaking.\n",
        "4.  SAP Data Automation\n",
        "•\tDeveloped automation solutions to streamline data management between Excel and SAP systems using Excel VBA and SAP automation features.\n",
        "•\tEnabled seamless updates of Excel data into SAP, enhancing operational efficiency and data accuracy across departments.\n",
        "5. Plastic Pollution Overview Dashboard\n",
        "•\tCreated a dynamic Tableau dashboard to visualize global plastic pollution metrics, including waste generation, recycling rates, and environmental impacts.\n",
        "•\tIntegrated multiple data sources and provided filters for regional and temporal analysis, offering actionable insights for stakeholders and supporting sustainability efforts.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2M477ZGcv_h"
      },
      "outputs": [],
      "source": [
        "# Desired Skill\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "api_key='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')\n",
        "\n",
        "# Set up the client\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles and other type of analyst roles\\n\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Step1: Extract all the keywords in the Job description which we need to use in resume. {jd} Step2: using the keyword extracted above and my resume  combine to generate an ideal resume for the job application.\n",
        "\n",
        "            Resume format:\n",
        "\n",
        "            *Work experience*\n",
        "            Company name\n",
        "            best suited 3 points with keywords very crisp and clear\n",
        "\n",
        "            *Projects*\n",
        "            you can generate new projects with difficulty level easy when some mandatory keywords or technology is missing in my work experience. Just choose top suited 3. Make the project name short and crisp like 2 words.\n",
        "            Title: \n",
        "            short idea in one line\n",
        "\n",
        "            {MyResume}\n",
        "            \"\"\"}\n",
        "\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "# Initialize a variable to store the output\n",
        "DesiredSkill = \"\"\n",
        "\n",
        "# Collect the response from the stream and store it\n",
        "for chunk in completion:\n",
        "    # Extract the content from the streamed chunk\n",
        "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
        "    DesiredSkill += content  # Append to the variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5F7_7t5zvXr"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "api_key='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')\n",
        "    \n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles, and other types of analyst roles.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{DesiredSkill}\\n\\nPlease generate the updated resume sections in YAML format using the same structure as provided below. Make sure the output is valid YAML without any markdown formatting (i.e., no triple backticks) so it can be directly loaded by a YAML parser. Also, include keywords from the project as a side heading in the 'projects' section.\\n\\n\"\n",
        "            \"\"\"{'work_experience': [{'title': , \n",
        "                                   'company': , \n",
        "                                   'dates': , \n",
        "                                   'achievements': []}], \n",
        "              'projects': [{'project_name': , \n",
        "                            'description': , \n",
        "                            'keywords': []}]}\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_completion_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "# Initialize a variable to store the output\n",
        "llm_yaml = \"\"\n",
        "\n",
        "# Collect the response from the stream and store it\n",
        "for chunk in completion:\n",
        "    # Extract the content from the streamed chunk\n",
        "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
        "    llm_yaml += content  # Append to the variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YAML file updated successfully.\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "\n",
        "# Load your existing YAML file\n",
        "yaml_file_path = r'C:\\Users\\karth\\OneDrive\\Documents\\GitHub\\pdf-build\\karthik.yaml'\n",
        "with open(yaml_file_path, 'r') as f:\n",
        "    resume_data = yaml.safe_load(f)\n",
        "\n",
        "# Load the new YAML content from the LLM output\n",
        "new_data = yaml.safe_load(llm)\n",
        "\n",
        "# # Update specific parts of your resume, e.g., work and projects sections\n",
        "for i in range(3):\n",
        "    resume_data[\"work\"][i]['highlights'] = new_data['work_experience'][i]['achievements']\n",
        "    resume_data['projects'][i]['description'] = new_data['projects'][i]['description']\n",
        "    resume_data['projects'][i]['keywords'] = new_data['projects'][i]['keywords']\n",
        "\n",
        "# for i in range(len(resume_data['projects'])):\n",
        "resume_data['projects'][0]['name'] = new_data['projects'][0]['project_name']\n",
        "resume_data['projects'][1]['name'] = new_data['projects'][1]['project_name']\n",
        "resume_data['projects'][2]['name'] = new_data['projects'][2]['project_name']\n",
        "\n",
        "with open(\"output.yaml\", 'w') as f:\n",
        "    yaml.safe_dump(resume_data, f)\n",
        "\n",
        "print(\"YAML file updated successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated HTML content:\n",
            "Attempting to create resume PDF at: resume.pdf\n",
            "the directory is \n",
            "SUCCESS: PDF created at resume.pdf\n"
          ]
        }
      ],
      "source": [
        "!python resumy.py build -o resume.pdf output.yaml"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPCaZx/Db0SJumCv0pb9W3i",
      "include_colab_link": true,
      "mount_file_id": "https://github.com/KarthikeyanBaskaran/pdf-build/blob/main/Resume_Generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
