{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement yaml (from versions: none)\n",
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "ERROR: No matching distribution found for yaml\n"
          ]
        }
      ],
      "source": [
        "!pip install dotenv groq yaml weasyprint --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6rCgqRLsZqUs"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "envpath = find_dotenv()\n",
        "load_dotenv(envpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "jd = input('Enter the job description here')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = r'C:\\Users\\karth\\OneDrive\\Documents\\GitHub\\pdf-build\\Resume.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "    MyResume = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "R2M477ZGcv_h"
      },
      "outputs": [],
      "source": [
        "client = Groq(api_key= os.getenv(\"grok_api\"))\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles and other type of analyst roles\\n\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Step1: Extract all the keywords in the Job description which we need to use in resume. {jd} Step2: using the keyword extracted above and my resume  combine to generate an ideal resume for the job application.\n",
        "\n",
        "            Resume format:\n",
        "\n",
        "            *Work experience*\n",
        "            Company name\n",
        "            best suited 3 points with keywords very crisp and clear\n",
        "\n",
        "            *Projects*\n",
        "            you can generate new projects with difficulty level easy when some mandatory keywords or technology is missing in my work experience. Make the project name short and crisp like 3 words. Finally Just choose top suited 3 projects to list.\n",
        "            Title: \n",
        "            short idea in one line\n",
        "\n",
        "            {MyResume}\n",
        "            \"\"\"}\n",
        "\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "DesiredSkill = \"\"\n",
        "\n",
        "for chunk in completion:\n",
        "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
        "    DesiredSkill += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the job description, I have extracted the following keywords:\n",
            "\n",
            "* Data science\n",
            "* Machine learning\n",
            "* Data visualization\n",
            "* Python\n",
            "* R\n",
            "* Power BI\n",
            "* Excel\n",
            "* SQL\n",
            "* Data architecture\n",
            "* Data warehousing\n",
            "* ETL pipelines\n",
            "* Data governance\n",
            "* Data quality\n",
            "* Statistical analysis\n",
            "* Data mining\n",
            "* Natural language processing\n",
            "* Artificial intelligence\n",
            "* Data storytelling\n",
            "* Communication\n",
            "* Collaboration\n",
            "* Stakeholder management\n",
            "\n",
            "Using these keywords, I have reviewed your resume and suggested the following:\n",
            "\n",
            "**Work Experience:**\n",
            "\n",
            "1. Procurement Engineer, Vestas Wind Technology, India (Nov 2021 – Aug 2023)\n",
            "\t* Utilized Python and SQL to analyze procurement data, uncovering opportunities for cost optimization worth $500K+ annually, demonstrating expertise in **data analysis** and **statistical analysis**.\n",
            "\t* Developed Power BI dashboards to track procurement KPIs, cutting reporting time by 40% and enhancing supplier performance monitoring, showcasing **data visualization** and **data storytelling** skills.\n",
            "\t* Implemented risk mitigation strategies by analyzing supply chain data and identifying alternative sourcing options to address potential delivery bottlenecks, highlighting **data-driven decision-making** and **problem-solving** abilities.\n",
            "2. Consultant ECM Purchaser, Vestas, ManpowerGroup Services, India (Jan 2021 – Nov 2021)\n",
            "\t* Developed and deployed cloud-based automation tools, resulting in a 30% increase in team productivity and faster completion of routine tasks, demonstrating **data engineering** and **process optimization** skills.\n",
            "\t* Built Python-based automation scripts, optimizing internal workflows and reducing manual effort by 25%, enhancing team efficiency, and showcasing **automation** and **data management** expertise.\n",
            "3. Procurement Engineer, Valeo India, India (Jun 2018 – Jan 2021)\n",
            "\t* Utilized Python and SQL to analyze procurement data, uncovering opportunities for cost optimization worth $500K+ annually, demonstrating **data analysis** and **statistical analysis** skills.\n",
            "\t* Developed Power BI dashboards to track procurement KPIs, cutting reporting time by 40% and enhancing supplier performance monitoring, showcasing **data visualization** and **data storytelling** skills.\n",
            "\n",
            "**Projects:**\n",
            "\n",
            "1. **Data Insights Dashboard**\n",
            "\t* Developed an interactive Tableau dashboard to analyze key financial KPIs such as P/E Ratio, Current Ratio, and Debt to Equity, demonstrating **data visualization** and **data storytelling** skills.\n",
            "2. **Customer Churn Analysis**\n",
            "\t* Designed and implemented an ETL pipeline in Python to clean and process large ecommerce customer datasets, showcasing **data engineering** and **data management** expertise.\n",
            "3. **Vestas Process Automation**\n",
            "\t* Automated employee data collection, analysis, and visualization processes using Power BI, Python, and Excel, demonstrating **automation** and **data management** skills.\n",
            "\n",
            "I have selected these projects as they demonstrate your ability to work with data, develop automation solutions, and create interactive dashboards, which are all relevant to the Junior Data Scientist role. The projects also showcase your skills in data analysis, statistical analysis, data visualization, and data storytelling, which are essential for the position. Additionally, the projects demonstrate your ability to work with various tools and technologies, such as Python, SQL, Power BI, and Excel, which are also relevant to the role.\n"
          ]
        }
      ],
      "source": [
        "print(DesiredSkill)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z5F7_7t5zvXr"
      },
      "outputs": [],
      "source": [
        "client = Groq(api_key= os.getenv(\"grok_api\"))\n",
        "    \n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles, and other types of analyst roles.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{DesiredSkill}\\n\\nPlease generate the updated resume sections in YAML format using the same structure as provided below. Make sure the output is valid YAML without any markdown formatting (i.e., no triple backticks) so it can be directly loaded by a YAML parser. Also, include keywords from the project as a side heading in the 'projects' section.\\n\\n\"\n",
        "            \"\"\"{'work_experience': [{'title': , \n",
        "                                   'company': , \n",
        "                                   'dates': , \n",
        "                                   'achievements': []}], \n",
        "              'projects': [{'project_name': , \n",
        "                            'description': , \n",
        "                            'keywords': []}]}\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_completion_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "llm_yaml = \"\"\n",
        "\n",
        "for chunk in completion:\n",
        "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
        "    llm_yaml += content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "work_experience:\n",
            "  - title: Procurement Engineer\n",
            "    company: Vestas Wind Technology, India\n",
            "    dates: Nov 2021 - Aug 2023\n",
            "    achievements:\n",
            "      - Utilized Python and SQL to analyze procurement data, uncovering opportunities for cost optimization worth $500K+ annually, demonstrating expertise in data analysis and statistical analysis.\n",
            "      - Developed Power BI dashboards to track procurement KPIs, cutting reporting time by 40% and enhancing supplier performance monitoring, showcasing data visualization and data storytelling skills.\n",
            "      - Implemented risk mitigation strategies by analyzing supply chain data and identifying alternative sourcing options to address potential delivery bottlenecks, highlighting data-driven decision-making and problem-solving abilities.\n",
            "  - title: Consultant ECM Purchaser\n",
            "    company: Vestas, ManpowerGroup Services, India\n",
            "    dates: Jan 2021 - Nov 2021\n",
            "    achievements:\n",
            "      - Developed and deployed cloud-based automation tools, resulting in a 30% increase in team productivity and faster completion of routine tasks, demonstrating data engineering and process optimization skills.\n",
            "      - Built Python-based automation scripts, optimizing internal workflows and reducing manual effort by 25%, enhancing team efficiency, and showcasing automation and data management expertise.\n",
            "  - title: Procurement Engineer\n",
            "    company: Valeo India, India\n",
            "    dates: Jun 2018 - Jan 2021\n",
            "    achievements:\n",
            "      - Utilized Python and SQL to analyze procurement data, uncovering opportunities for cost optimization worth $500K+ annually, demonstrating data analysis and statistical analysis skills.\n",
            "      - Developed Power BI dashboards to track procurement KPIs, cutting reporting time by 40% and enhancing supplier performance monitoring, showcasing data visualization and data storytelling skills.\n",
            "\n",
            "projects:\n",
            "  - project_name: Data Insights Dashboard\n",
            "    description: Developed an interactive Tableau dashboard to analyze key financial KPIs such as P/E Ratio, Current Ratio, and Debt to Equity.\n",
            "    keywords: \n",
            "      - data visualization\n",
            "      - data storytelling\n",
            "      - Tableau\n",
            "      - financial analysis\n",
            "  - project_name: Customer Churn Analysis\n",
            "    description: Designed and implemented an ETL pipeline in Python to clean and process large ecommerce customer datasets.\n",
            "    keywords: \n",
            "      - data engineering\n",
            "      - data management\n",
            "      - ETL pipelines\n",
            "      - Python\n",
            "      - customer churn analysis\n",
            "  - project_name: Vestas Process Automation\n",
            "    description: Automated employee data collection, analysis, and visualization processes using Power BI, Python, and Excel.\n",
            "    keywords: \n",
            "      - automation\n",
            "      - data management\n",
            "      - Power BI\n",
            "      - Python\n",
            "      - Excel\n",
            "      - process optimization\n"
          ]
        }
      ],
      "source": [
        "print(llm_yaml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = Groq(api_key= os.getenv(\"grok_api\"))\n",
        "    \n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles, and other types of analyst roles.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"based on resume and job description i need skills and summary in the below format to include in my resume\\n\\njob description\\n\\\"\\\"\\\"{jd}\\n\\nresume \\\"\\\"\\\"{llm_yaml}\\\"\\\"\\\"\\n\\n\n",
        "            FORMAT:\n",
        "            summary:\n",
        "            skills:\n",
        "            -  name: maximum 6 names\n",
        "               keywords: [max 3 well suited skills, do not repeat same skills]\n",
        "               \n",
        "            NO PREAMBLE, Yaml format\\n\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_completion_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "skillyaml = \"\"\n",
        "\n",
        "for chunk in completion:\n",
        "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
        "    skillyaml += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "summary: Results-driven data professional with experience in data analysis, visualization, and process optimization, seeking a Junior Data Scientist role to leverage technical skills and drive business growth.\n",
            "\n",
            "skills:\n",
            "  - name: Data Analysis\n",
            "    keywords: [Python, SQL, Statistical Analysis]\n",
            "  - name: Data Visualization\n",
            "    keywords: [Power BI, Tableau, Data Storytelling]\n",
            "  - name: Data Engineering\n",
            "    keywords: [ETL Pipelines, Data Management, Automation]\n",
            "  - name: Process Optimization\n",
            "    keywords: [Python, Automation, Cloud-Based Tools]\n",
            "  - name: Business Intelligence\n",
            "    keywords: [Data Visualization, Reporting, Dashboards]\n",
            "  - name: Technical Development\n",
            "    keywords: [Python, Machine Learning, Data Science]\n"
          ]
        }
      ],
      "source": [
        "print(skillyaml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YAML file updated successfully.\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "yaml_file_path = r'C:\\Users\\karth\\OneDrive\\Documents\\GitHub\\pdf-build\\karthik.yaml'\n",
        "with open(yaml_file_path, 'r') as f:\n",
        "    resume_data = yaml.safe_load(f)\n",
        "\n",
        "exp_data = yaml.safe_load(llm_yaml)\n",
        "skill_data = yaml.safe_load(skillyaml)\n",
        "\n",
        "resume_data['basics']['summary'] = skill_data['summary']\n",
        "\n",
        "#work experience\n",
        "for i in range(len(exp_data['work_experience'])):\n",
        "    resume_data[\"work\"][i]['highlights'] = exp_data['work_experience'][i]['achievements']\n",
        "\n",
        "for i in range(len(exp_data['projects'])):\n",
        "    resume_data['projects'][i]['description'] = exp_data['projects'][i]['description']\n",
        "    resume_data['projects'][i]['keywords'] = exp_data['projects'][i]['keywords']\n",
        "    resume_data['projects'][i]['name'] = exp_data['projects'][i]['project_name']\n",
        "\n",
        "for i in range(len(skill_data['skills'])):\n",
        "    resume_data['skills'][i]['keywords'] = skill_data['skills'][i]['keywords']\n",
        "    resume_data['skills'][i]['name'] = skill_data['skills'][i]['name']\n",
        "    \n",
        "\n",
        "with open(\"output.yaml\", 'w') as f:\n",
        "    yaml.safe_dump(resume_data, f)\n",
        "\n",
        "print(\"YAML file updated successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Developed and deployed cloud-based automation tools, resulting in a 30% increase in team productivity and faster completion of routine tasks, demonstrating data engineering and process optimization skills.',\n",
              " 'Built Python-based automation scripts, optimizing internal workflows and reducing manual effort by 25%, enhancing team efficiency, and showcasing automation and data management expertise.']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resume_data[\"work\"][1]['highlights']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated HTML content:\n",
            "resume.pdf\n",
            "HTML file saved as: template.html\n",
            "SUCCESS: PDF created at resume.pdf\n"
          ]
        }
      ],
      "source": [
        "!python resumy.py build -o resume.pdf output.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPCaZx/Db0SJumCv0pb9W3i",
      "include_colab_link": true,
      "mount_file_id": "https://github.com/KarthikeyanBaskaran/pdf-build/blob/main/Resume_Generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
