{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dotenv groq PyYAML weasyprint --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "6rCgqRLsZqUs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "envpath = find_dotenv()\n",
    "load_dotenv(envpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = input('Enter the job description here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\karth\\OneDrive\\Documents\\GitHub\\pdf-build\\Resume.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    MyResume = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "R2M477ZGcv_h"
   },
   "outputs": [],
   "source": [
    "client = Groq(api_key= os.getenv(\"grok_api\"))\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles and other type of analyst roles\\n\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            Instruction\n",
    "            Using the keyword extracted from the job description and my resume combine to generate an ideal resume for the job application.\n",
    "\n",
    "            Resume format:\n",
    "\n",
    "            *Work experience*\n",
    "            Company name\n",
    "            best suited 3 points from my resume and rewrite them to highlight transferable skills and quantify achievements\n",
    "            Use action verbs and measurable results (e.g., reduced, improved, increased by X%).\n",
    "\n",
    "\n",
    "            *Projects*\n",
    "            you can generate new projects with difficulty level easy when some mandatory keywords or technology is missing in my work experience. Make the project title short and crisp( 3 words ). Finally Just choose top suited 3 projects to list.\n",
    "            Title: \n",
    "            short idea in one line\n",
    "\n",
    "            Resume : {MyResume}\n",
    "            JOb Description : {jd}\n",
    "\n",
    "            \"\"\"}\n",
    "\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    ")\n",
    "DesiredSkill = \"\"\n",
    "\n",
    "for chunk in completion:\n",
    "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
    "    DesiredSkill += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the job description and your resume, I've highlighted the top 3 work experience points that can be rewritten to showcase transferable skills and quantify achievements:\n",
      "\n",
      "**Work Experience:**\n",
      "Company Name: Vestas Wind Technology, India\n",
      "\n",
      "* Developed and maintained comprehensive Power BI dashboards to track KPIs, supplier performance, and category spend, empowering leadership with informed decision-making capabilities and improving data-driven insights by 25%.\n",
      "* Implemented data transformations and visualizations using Power BI, resulting in a 30% reduction in manual efforts and enhancing data accuracy across departments.\n",
      "* Collaborated with cross-functional teams to design data models, create reports, and implement data warehousing concepts, delivering scalable and efficient business intelligence solutions that improved stakeholder engagement by 20%.\n",
      "\n",
      "And here are the top 3 project points that can be highlighted:\n",
      "\n",
      "**Projects:**\n",
      "1. **Vestas KPI Tracking**: Automated employee data collection, analysis, and visualization processes using Power BI, Python, and Excel, improving traceability and key metric visibility, and significantly benefiting senior management decision-making.\n",
      "2. **Meta Financial Dashboard**: Developed an interactive Tableau dashboard to analyze key financial KPIs, delivering actionable insights that improved financial decision making, enhancing reporting accuracy, and strategic planning.\n",
      "3. **SAP Data Automation**: Developed automation solutions to streamline data management of SAP using Excel VBA and SAP automation features, enabling seamless updates, enhancing operational efficiency, and data accuracy across departments.\n",
      "\n",
      "These rewritten points aim to showcase your skills in Power BI development, data modeling, and collaboration, which are essential for the Power BI Developer role. The projects highlighted demonstrate your ability to work with various tools and technologies, including Power BI, Tableau, and SAP, and your expertise in data analysis and visualization.\n"
     ]
    }
   ],
   "source": [
    "print(DesiredSkill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "z5F7_7t5zvXr"
   },
   "outputs": [],
   "source": [
    "client = Groq(api_key= os.getenv(\"grok_api\"))\n",
    "    \n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles, and other types of analyst roles.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{DesiredSkill}\\n\\nPlease generate the updated resume sections in YAML format using the same structure as provided below. Make sure the output is valid YAML without any markdown formatting (i.e., no triple backticks) so it can be directly loaded by a YAML parser. Also, include keywords from the project as a side heading in the 'projects' section.\\n\\n\"\n",
    "            \"\"\"{'work_experience': [{'title': , \n",
    "                                   'company': , \n",
    "                                   'dates': , \n",
    "                                   'achievements': []}], \n",
    "              'projects': [{'project_name': , \n",
    "                            'description': , \n",
    "                            'keywords': []}]}\"\"\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "llm_yaml = \"\"\n",
    "\n",
    "for chunk in completion:\n",
    "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
    "    llm_yaml += content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_experience:\n",
      "  - title: Data Analyst\n",
      "    company: Vestas Wind Technology, India\n",
      "    dates: \n",
      "    achievements:\n",
      "      - Developed and maintained comprehensive Power BI dashboards to track KPIs, supplier performance, and category spend, empowering leadership with informed decision-making capabilities and improving data-driven insights by 25%.\n",
      "      - Implemented data transformations and visualizations using Power BI, resulting in a 30% reduction in manual efforts and enhancing data accuracy across departments.\n",
      "      - Collaborated with cross-functional teams to design data models, create reports, and implement data warehousing concepts, delivering scalable and efficient business intelligence solutions that improved stakeholder engagement by 20%.\n",
      "\n",
      "projects:\n",
      "  - project_name: Vestas KPI Tracking\n",
      "    description: Automated employee data collection, analysis, and visualization processes using Power BI, Python, and Excel, improving traceability and key metric visibility, and significantly benefiting senior management decision-making.\n",
      "    keywords: [Power BI, Python, Excel, Automation, KPI Tracking]\n",
      "  - project_name: Meta Financial Dashboard\n",
      "    description: Developed an interactive Tableau dashboard to analyze key financial KPIs, delivering actionable insights that improved financial decision making, enhancing reporting accuracy, and strategic planning.\n",
      "    keywords: [Tableau, Financial Analysis, Dashboard, KPIs]\n",
      "  - project_name: SAP Data Automation\n",
      "    description: Developed automation solutions to streamline data management of SAP using Excel VBA and SAP automation features, enabling seamless updates, enhancing operational efficiency, and data accuracy across departments.\n",
      "    keywords: [SAP, Excel VBA, Automation, Data Management]\n"
     ]
    }
   ],
   "source": [
    "print(llm_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key= os.getenv(\"grok_api\"))\n",
    "    \n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles, and other types of analyst roles.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"based on resume and job description i need skills and write a powerful 1-line professional summary that hooks a recruiter in under 10 seconds.\\n\\n\n",
    "            job description{jd}\n",
    "            resume {llm_yaml}\n",
    "            \n",
    "            FORMAT:\n",
    "            summary:\n",
    "            skills:\n",
    "            -  name: maximum 6 names\n",
    "               keywords: [max 3 well suited skills, do not repeat same skills]\n",
    "               \n",
    "            NO PREAMBLE, Yaml format\\n\"\"\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "skillyaml = \"\"\n",
    "\n",
    "for chunk in completion:\n",
    "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
    "    skillyaml += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary: Results-driven Power BI Developer with 25% improvement in data-driven insights, leveraging expertise in Power BI, DAX, and SQL to deliver scalable business intelligence solutions.\n",
      "skills:\n",
      "  - name: Power BI\n",
      "    keywords: [Data Visualization, Business Intelligence, Data Modeling]\n",
      "  - name: Data Warehousing\n",
      "    keywords: [Data Storage, ETL, Data Governance]\n",
      "  - name: SQL\n",
      "    keywords: [Data Analysis, Querying, Database Management]\n",
      "  - name: DAX\n",
      "    keywords: [Data Modeling, Calculations, Measures]\n",
      "  - name: Data Analysis\n",
      "    keywords: [Reporting, Dashboarding, Insights]\n",
      "  - name: Collaboration\n",
      "    keywords: [Stakeholder Management, Requirements Gathering, Teamwork]\n"
     ]
    }
   ],
   "source": [
    "print(skillyaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary: Results-driven Power BI Developer with 25% improvement in data-driven insights, leveraging expertise in Power BI, DAX, and SQL to deliver scalable business intelligence solutions.\n",
      "skills:\n",
      "  - name: Power BI\n",
      "    keywords: [Data Visualization, Business Intelligence, Data Modeling]\n",
      "  - name: Data Warehousing\n",
      "    keywords: [Data Storage, ETL, Data Governance]\n",
      "  - name: SQL\n",
      "    keywords: [Data Analysis, Querying, Database Management]\n",
      "  - name: DAX\n",
      "    keywords: [Data Modeling, Calculations, Measures]\n",
      "  - name: Data Analysis\n",
      "    keywords: [Reporting, Dashboarding, Insights]\n",
      "  - name: Collaboration\n",
      "    keywords: [Stakeholder Management, Requirements Gathering, Teamwork]\n"
     ]
    }
   ],
   "source": [
    "print(skillyaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_data = yaml.safe_load(skillyaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "yaml_file_path = r'C:\\Users\\karth\\OneDrive\\Documents\\GitHub\\pdf-build\\karthik.yaml'\n",
    "with open(yaml_file_path, 'r') as f:\n",
    "    resume_data = yaml.safe_load(f)\n",
    "\n",
    "exp_data = yaml.safe_load(llm_yaml)\n",
    "skill_data = yaml.safe_load(skillyaml)\n",
    "\n",
    "resume_data['basics']['summary'] = skill_data['summary']\n",
    "\n",
    "#work experience\n",
    "for i in range(len(exp_data['work_experience'])):\n",
    "    resume_data[\"work\"][i]['highlights'] = exp_data['work_experience'][i]['achievements']\n",
    "\n",
    "for i in range(len(exp_data['projects'])):\n",
    "    resume_data['projects'][i]['description'] = exp_data['projects'][i]['description']\n",
    "    resume_data['projects'][i]['keywords'] = exp_data['projects'][i]['keywords']\n",
    "    resume_data['projects'][i]['name'] = exp_data['projects'][i]['project_name']\n",
    "\n",
    "for i in range(len(skill_data['skills'])):\n",
    "    resume_data['skills'][i]['keywords'] = skill_data['skills'][i]['keywords']\n",
    "    resume_data['skills'][i]['name'] = skill_data['skills'][i]['name']\n",
    "    \n",
    "\n",
    "with open(\"output.yaml\", 'w') as f:\n",
    "    yaml.safe_dump(resume_data, f)\n",
    "\n",
    "print(\"YAML file updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Developed predictive analytics models for demand forecasting, improving delivery timelines by 20%.',\n",
       " 'Automated internal workflows using Python and Power Query, enhancing team efficiency by 30%.',\n",
       " 'Designed a procurement dashboard using Power BI and Cloud Storage.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_data[\"work\"][1]['highlights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated HTML content:\n",
      "resume.pdf\n",
      "HTML file saved as: template.html\n",
      "SUCCESS: PDF created at resume.pdf\n"
     ]
    }
   ],
   "source": [
    "!python resumy.py build -o resume.pdf output.yaml"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPCaZx/Db0SJumCv0pb9W3i",
   "include_colab_link": true,
   "mount_file_id": "https://github.com/KarthikeyanBaskaran/pdf-build/blob/main/Resume_Generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
