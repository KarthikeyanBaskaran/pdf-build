{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rCgqRLsZqUs"
      },
      "outputs": [],
      "source": [
        "# !pip install --quiet groq pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "jd = input('Enter the job description here')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = r'C:\\Users\\karth\\OneDrive\\Documents\\GitHub\\pdf-build\\Resume.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "    MyResume = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "i3Ya1muycJh3"
      },
      "outputs": [],
      "source": [
        "# MyResume = \"\"\"Professional Experience:\n",
        "# 1. Procurement Engineer, Vestas Wind Technology, India (Nov 2021 – Aug 2023):\n",
        "# •\tAchieved a 15% reduction in procurement costs by developing a data-driven supplier evaluation model and conducting detailed cost analysis.\n",
        "# •\tImproved project timelines by 20% through predictive analytics for demand forecasting and proactive delay management.\n",
        "# •\tSaved $85M annually by developing and implementing Python-based automation tools, streamlining procurement workflows and enhancing operational efficiency.\n",
        "# •\tEnhanced supplier performance monitoring by designing vendor scorecards using Excel and Power BI, enabling data visualization for better decision-making.\n",
        "# •\tIntegrated IT systems into procurement processes, deploying Microsoft Power Query and SharePoint to automate reporting and improve data accuracy, reducing manual efforts by 30%.\n",
        "# •\tDeveloped a procurement dashboard in Power BI to track KPIs, supplier performance, and category spend, enabling leadership to make informed decisions.\n",
        "# •\tOptimized material master data accuracy through automation, improving data consistency and reducing errors by 25%.\n",
        "# •\tCollaborated with IT and cross-functional teams to develop scalable software solutions for supply chain monitoring, ensuring seamless integration with existing systems.\n",
        "# •\tImplemented risk mitigation strategies by analyzing supply chain data and identifying alternative sourcing options to address potential delivery bottlenecks.\n",
        "# •\tStreamlined RFQ processes using advanced quote comparison tools and automation, reducing processing time by 40%.\n",
        "# •\tNegotiated supplier contracts to achieve cost savings and ensure compliance with government policies, leveraging IT tools for real-time data tracking.\n",
        "# •\tDesigned and deployed customized procurement strategies to handle delivery complexities, ensuring continuity in production and minimizing downtime.\n",
        "# •\tImproved KPI tracking by automating SLA adherence reporting, increasing visibility for stakeholders and reducing manual intervention.\n",
        "# •\tLed IT-driven innovations in procurement by identifying opportunities for automation and implementing solutions that enhanced scalability and flexibility across procurement functions.\n",
        "\n",
        "# 2. Consultant ECM Purchaser, Vestas, ManpowerGroup Services, India (Jan 2021 – Nov 2021):\n",
        "# •\tReduced production costs by 10% through process optimization analyses, utilizing data-driven insights to streamline operations.\n",
        "# •\tIdentified potential savings of €3M by analyzing supplier costs and payment credit periods, implementing standardized and efficient procurement strategies.\n",
        "# •\tImproved operational efficiency by 15% by leading cross-functional collaboration and deploying Lean methodologies.\n",
        "# •\tEnhanced project delivery capacity by 20% through process improvements that freed up resources for handling additional projects.\n",
        "# •\tDeveloped and deployed cloud-based automation tools, resulting in a 30% increase in team productivity and faster completion of routine tasks.\n",
        "# •\tLed RFx processes across wind turbine segments, negotiating competitive pricing with global vendors and achieving an 8% reduction in procurement costs.\n",
        "# •\tCollaborated with product management and design teams to define project scope and requirements, ensuring alignment with customer needs and delivering projects 10% faster.\n",
        "# •\tBuilt Python-based automation scripts, optimizing internal workflows and reducing manual effort by 25%, enhancing team efficiency.\n",
        "# •\tStrengthened stakeholder relationships by implementing efficient communication strategies, improving supplier and sponsor engagement by 12%.\n",
        "# •\tDeveloped dashboards and reporting tools using Python and cloud services to monitor KPIs, improving decision-making accuracy by 18%.\n",
        "\n",
        "# 3. Procurement Engineer, Valeo India, India (Jun 2018 – Jan 2021):\n",
        "# •\tManaged RFx processes across global wind turbine segments, achieving 10-15% cost reductions through competitive vendor sourcing and procurement strategies.\n",
        "# •\tBuilt and maintained a robust supplier base by inducting vendors, implementing double sourcing, and driving localization, resulting in a 20% improvement in supply chain efficiency.\n",
        "# •\tExecuted supplier auctions using digital platforms, reducing overall part costs by 8-12% while ensuring competitive pricing.\n",
        "# •\tPerformed zero-based costing using advanced Excel (macros, pivot tables) and analytical tools, enabling 15% cost savings through data-driven negotiations.\n",
        "# •\tDeveloped Power BI dashboards to track procurement KPIs, cutting reporting time by 40% and enhancing supplier performance monitoring.\n",
        "# •\tUtilized Python and SQL to analyze procurement data, uncovering opportunities for cost optimization worth $500K+ annually.\n",
        "# •\tIntegrated ERP tools (SAP) to streamline procurement workflows, reducing manual effort by 30% and enhancing process accuracy.\n",
        "# •\tSourced globally from cost-effective suppliers to meet production demands, ensuring 100% on-time delivery and adherence to quality standards.\n",
        "# •\tGained expertise in manufacturing techniques, achieving a 10% reduction in project costs by aligning processes with best-cost practices.\n",
        "# •\tCollaborated on ERP system enhancements, reducing procurement cycle times by 20% and improving data accessibility for stakeholders.\n",
        "\n",
        "\n",
        "# Education:\n",
        "#  Diploma in Data Analytics for Business, St. Clair College (2024):\n",
        "#  GPA: 4.0\n",
        "#     Relevant coursework: Data Mining, Predictive Analytics, Database Management, and Machine Learning.\n",
        "\n",
        "#  Bachelor of Engineering, Mechanical,  St. Joseph’s institute of Technology (2024):\n",
        "#    GPA: 3.5\n",
        "\n",
        "# Certifications:\n",
        "#  SQL for Data Science (Coursera)\n",
        "#  Python for Data Analysis (Udemy)\n",
        "#  Tableau Desktop Specialist Certification\n",
        "\n",
        "# #### Projects:\n",
        "# 1. Meta Financial Dashboard\n",
        "# •\tDeveloped an interactive Tableau dashboard to analyze key financial KPIs such as P/E Ratio, Current Ratio, and Debt to Equity.\n",
        "# •\tDelivered actionable insights that improved financial decisionmaking, enhancing reporting accuracy and strategic planning.\n",
        "# 2. Customer Churn Analysis\n",
        "# •\tDesigned and implemented an ETL pipeline in Python to clean and process large ecommerce customer datasets.\n",
        "# •\tPerformed predictive analytics to identify highrisk churn customers, leading to targeted retention strategies and a measurable reduction in churn rates.\n",
        "# 3. Vestas Process Automation\n",
        "# •\tAutomated employee data collection, analysis, and visualization processes using Power BI, Python, and Excel.\n",
        "# •\tLeveraged Microsoft Power Query for streamlined internal data gathering, improving traceability and key metric visibility, significantly benefiting senior management decisionmaking.\n",
        "# 4.  SAP Data Automation\n",
        "# •\tDeveloped automation solutions to streamline data management between Excel and SAP systems using Excel VBA and SAP automation features.\n",
        "# •\tEnabled seamless updates of Excel data into SAP, enhancing operational efficiency and data accuracy across departments.\n",
        "# 5. Plastic Pollution Overview Dashboard\n",
        "# •\tCreated a dynamic Tableau dashboard to visualize global plastic pollution metrics, including waste generation, recycling rates, and environmental impacts.\n",
        "# •\tIntegrated multiple data sources and provided filters for regional and temporal analysis, offering actionable insights for stakeholders and supporting sustainability efforts.\n",
        "\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "R2M477ZGcv_h"
      },
      "outputs": [],
      "source": [
        "# Desired Skill\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "api_key='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')\n",
        "\n",
        "# Set up the client\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles and other type of analyst roles\\n\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Step1: Extract all the keywords in the Job description which we need to use in resume. {jd} Step2: using the keyword extracted above and my resume  combine to generate an ideal resume for the job application.\n",
        "\n",
        "            Resume format:\n",
        "\n",
        "            *Work experience*\n",
        "            Company name\n",
        "            best suited 3 points with keywords very crisp and clear\n",
        "\n",
        "            *Projects*\n",
        "            you can generate new projects with difficulty level easy when some mandatory keywords or technology is missing in my work experience. Just choose top suited 3. Make the project name short and crisp like 2 words.\n",
        "            Title: \n",
        "            short idea in one line\n",
        "\n",
        "            {MyResume}\n",
        "            \"\"\"}\n",
        "\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "# Initialize a variable to store the output\n",
        "DesiredSkill = \"\"\n",
        "\n",
        "# Collect the response from the stream and store it\n",
        "for chunk in completion:\n",
        "    # Extract the content from the streamed chunk\n",
        "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
        "    DesiredSkill += content  # Append to the variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the job description, I extracted the following keywords:\n",
            "\n",
            "* Data Science\n",
            "* Data Engineering\n",
            "* SQL\n",
            "* New technologies\n",
            "* Proactive\n",
            "* Leadership\n",
            "* Communication\n",
            "* Teamwork\n",
            "* Safety mindset\n",
            "* Flexibility\n",
            "* Autonomy\n",
            "* Valid driving license\n",
            "* Computer science\n",
            "* Relevant experience\n",
            "* Python\n",
            "* Data analysis\n",
            "* Data visualization\n",
            "* Machine learning\n",
            "* Database management\n",
            "\n",
            "Using these keywords and your resume, I generated the following ideal resume for the job application:\n",
            "\n",
            "**Work Experience:**\n",
            "\n",
            "* Procurement Engineer, Vestas Wind Technology, India (Nov 2021 – Aug 2023)\n",
            "\t+ Developed and implemented data-driven supplier evaluation models using Python and SQL, achieving a 15% reduction in procurement costs.\n",
            "\t+ Utilized predictive analytics for demand forecasting, improving project timelines by 20% and enhancing operational efficiency.\n",
            "\t+ Designed and deployed Power BI dashboards to track KPIs, supplier performance, and category spend, enabling data-driven decision-making.\n",
            "* Consultant ECM Purchaser, Vestas, ManpowerGroup Services, India (Jan 2021 – Nov 2021)\n",
            "\t+ Analyzed supplier costs and payment credit periods using data-driven insights, identifying potential savings of €3M and implementing standardized procurement strategies.\n",
            "\t+ Developed and deployed cloud-based automation tools using Python, resulting in a 30% increase in team productivity and faster completion of routine tasks.\n",
            "\t+ Collaborated with cross-functional teams to define project scope and requirements, ensuring alignment with customer needs and delivering projects 10% faster.\n",
            "* Procurement Engineer, Valeo India, India (Jun 2018 – Jan 2021)\n",
            "\t+ Built and maintained a robust supplier base by inducting vendors, implementing double sourcing, and driving localization, resulting in a 20% improvement in supply chain efficiency.\n",
            "\t+ Executed supplier auctions using digital platforms, reducing overall part costs by 8-12% while ensuring competitive pricing.\n",
            "\t+ Utilized Python and SQL to analyze procurement data, uncovering opportunities for cost optimization worth $500K+ annually.\n",
            "\n",
            "**Projects:**\n",
            "\n",
            "* Data Science Dashboard\n",
            "\t+ Developed an interactive dashboard using Tableau to analyze key data science metrics, including data quality, process efficiency, and customer satisfaction.\n",
            "* Predictive Analytics Model\n",
            "\t+ Designed and implemented a predictive analytics model using Python and machine learning algorithms to forecast demand and optimize supply chain operations.\n",
            "* Data Visualization Project\n",
            "\t+ Created a dynamic data visualization dashboard using Power BI to track KPIs, supplier performance, and category spend, enabling data-driven decision-making.\n",
            "\n",
            "I generated new projects to highlight your skills in data science, data engineering, and data analysis, as these were missing from your work experience. The projects are designed to be easy to understand and demonstrate your ability to work with data-driven technologies.\n",
            "\n",
            "Please note that I've kept the projects short and crisp, with a focus on the keywords extracted from the job description. I've also ensured that the projects are relevant to the job application and demonstrate your skills in data science, data engineering, and data analysis.\n"
          ]
        }
      ],
      "source": [
        "print(DesiredSkill)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "z5F7_7t5zvXr"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "api_key='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')\n",
        "    \n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles, and other types of analyst roles.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{DesiredSkill}\\n\\nPlease generate the updated resume sections in YAML format using the same structure as provided below. Make sure the output is valid YAML without any markdown formatting (i.e., no triple backticks) so it can be directly loaded by a YAML parser. Also, include keywords from the project as a side heading in the 'projects' section.\\n\\n\"\n",
        "            \"\"\"{'work_experience': [{'title': , \n",
        "                                   'company': , \n",
        "                                   'dates': , \n",
        "                                   'achievements': []}], \n",
        "              'projects': [{'project_name': , \n",
        "                            'description': , \n",
        "                            'keywords': []}]}\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_completion_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "# Initialize a variable to store the output\n",
        "llm_yaml = \"\"\n",
        "\n",
        "# Collect the response from the stream and store it\n",
        "for chunk in completion:\n",
        "    # Extract the content from the streamed chunk\n",
        "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
        "    llm_yaml += content  # Append to the variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "work_experience:\n",
            "  - title: Procurement Engineer\n",
            "    company: Vestas Wind Technology, India\n",
            "    dates: Nov 2021 - Aug 2023\n",
            "    achievements:\n",
            "      - Developed and implemented data-driven supplier evaluation models using Python and SQL, achieving a 15% reduction in procurement costs.\n",
            "      - Utilized predictive analytics for demand forecasting, improving project timelines by 20% and enhancing operational efficiency.\n",
            "      - Designed and deployed Power BI dashboards to track KPIs, supplier performance, and category spend, enabling data-driven decision-making.\n",
            "  - title: Consultant ECM Purchaser\n",
            "    company: Vestas, ManpowerGroup Services, India\n",
            "    dates: Jan 2021 - Nov 2021\n",
            "    achievements:\n",
            "      - Analyzed supplier costs and payment credit periods using data-driven insights, identifying potential savings of €3M and implementing standardized procurement strategies.\n",
            "      - Developed and deployed cloud-based automation tools using Python, resulting in a 30% increase in team productivity and faster completion of routine tasks.\n",
            "      - Collaborated with cross-functional teams to define project scope and requirements, ensuring alignment with customer needs and delivering projects 10% faster.\n",
            "  - title: Procurement Engineer\n",
            "    company: Valeo India, India\n",
            "    dates: Jun 2018 - Jan 2021\n",
            "    achievements:\n",
            "      - Built and maintained a robust supplier base by inducting vendors, implementing double sourcing, and driving localization, resulting in a 20% improvement in supply chain efficiency.\n",
            "      - Executed supplier auctions using digital platforms, reducing overall part costs by 8-12% while ensuring competitive pricing.\n",
            "      - Utilized Python and SQL to analyze procurement data, uncovering opportunities for cost optimization worth $500K+ annually.\n",
            "projects:\n",
            "  - project_name: Data Science Dashboard\n",
            "    description: Developed an interactive dashboard using Tableau to analyze key data science metrics, including data quality, process efficiency, and customer satisfaction.\n",
            "    keywords: [Data Science, Data Visualization, Tableau]\n",
            "  - project_name: Predictive Analytics Model\n",
            "    description: Designed and implemented a predictive analytics model using Python and machine learning algorithms to forecast demand and optimize supply chain operations.\n",
            "    keywords: [Predictive Analytics, Machine Learning, Python]\n",
            "  - project_name: Data Visualization Project\n",
            "    description: Created a dynamic data visualization dashboard using Power BI to track KPIs, supplier performance, and category spend, enabling data-driven decision-making.\n",
            "    keywords: [Data Visualization, Power BI, Data Analysis]\n"
          ]
        }
      ],
      "source": [
        "print(llm_yaml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "api_key='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')\n",
        "    \n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a professional career coach and resume-writing assistant. Your task is to craft strong, impactful, and industry-relevant resume bullet points that make my profile stand out for data analytics, data engineering roles, and other types of analyst roles.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"based on resume and job description i need skills and summary in the below format to include in my resume\\n\\njob description\\n\\\"\\\"\\\"{jd}\\n\\nresume \\\"\\\"\\\"{llm_yaml}\\\"\\\"\\\"\\n\\n\n",
        "            FORMAT:\n",
        "            summary:\n",
        "            skills:\n",
        "            -  name: maximum 6 names\n",
        "               keywords: [max 5 well suited skills, do not repeat same skills]\n",
        "               \n",
        "            NO PREAMBLE, Yaml format\\n\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_completion_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "# Initialize a variable to store the output\n",
        "skillyaml = \"\"\n",
        "\n",
        "# Collect the response from the stream and store it\n",
        "for chunk in completion:\n",
        "    # Extract the content from the streamed chunk\n",
        "    content = chunk.choices[0].delta.content if chunk.choices[0].delta.content else \"\"\n",
        "    skillyaml += content  # Append to the variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "new_data = yaml.safe_load(skillyaml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(new_data['skills'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_data = yaml.safe_load(llm_yaml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'summary': 'Results-driven data analytics professional with experience in developing data-driven solutions, predictive analytics, and data visualization to drive business growth and improve operational efficiency.',\n",
              " 'skills': [{'name': 'Data Science',\n",
              "   'keywords': ['Machine Learning',\n",
              "    'Data Visualization',\n",
              "    'Predictive Analytics',\n",
              "    'Python',\n",
              "    'SQL',\n",
              "    'Tableau']},\n",
              "  {'name': 'Data Engineering',\n",
              "   'keywords': ['Data Quality',\n",
              "    'Process Efficiency',\n",
              "    'Customer Satisfaction',\n",
              "    'Power BI',\n",
              "    'Data Mining',\n",
              "    'Cloud Computing']},\n",
              "  {'name': 'Business Intelligence',\n",
              "   'keywords': ['Data Analysis',\n",
              "    'Data Visualization',\n",
              "    'KPIs',\n",
              "    'Supplier Performance',\n",
              "    'Category Spend',\n",
              "    'Dashboard Development']},\n",
              "  {'name': 'Predictive Modeling',\n",
              "   'keywords': ['Demand Forecasting',\n",
              "    'Supply Chain Optimization',\n",
              "    'Python',\n",
              "    'Machine Learning',\n",
              "    'Statistical Modeling',\n",
              "    'Data Analytics']},\n",
              "  {'name': 'Data Visualization',\n",
              "   'keywords': ['Tableau',\n",
              "    'Power BI',\n",
              "    'Data Storytelling',\n",
              "    'Interactive Dashboards',\n",
              "    'Data Insights',\n",
              "    'Business Decision-making']},\n",
              "  {'name': 'Analytics',\n",
              "   'keywords': ['Data-Driven Decision Making',\n",
              "    'Business Analytics',\n",
              "    'Operational Efficiency',\n",
              "    'Cost Optimization',\n",
              "    'Procurement Analytics',\n",
              "    'Supply Chain Management']}]}"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YAML file updated successfully.\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "\n",
        "# Load your existing YAML file\n",
        "yaml_file_path = r'C:\\Users\\karth\\OneDrive\\Documents\\GitHub\\pdf-build\\karthik.yaml'\n",
        "with open(yaml_file_path, 'r') as f:\n",
        "    resume_data = yaml.safe_load(f)\n",
        "\n",
        "# Load the new YAML content from the LLM output\n",
        "new_data = yaml.safe_load(llm_yaml)\n",
        "\n",
        "# Update specific parts of your resume, e.g., work and projects sections\n",
        "for i in range(3):\n",
        "    resume_data[\"work\"][i]['highlights'] = new_data['work_experience'][i]['achievements']\n",
        "    resume_data['projects'][i]['description'] = new_data['projects'][i]['description']\n",
        "    resume_data['projects'][i]['keywords'] = new_data['projects'][i]['keywords']\n",
        "    resume_data['projects'][i]['name'] = new_data['projects'][i]['project_name']\n",
        "\n",
        "# for i in range(len(resume_data['projects'])):\n",
        "\n",
        "# resume_data['projects'][1]['name'] = new_data['projects'][1]['project_name']\n",
        "# resume_data['projects'][2]['name'] = new_data['projects'][2]['project_name']\n",
        "\n",
        "with open(\"output.yaml\", 'w') as f:\n",
        "    yaml.safe_dump(resume_data, f)\n",
        "\n",
        "print(\"YAML file updated successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated HTML content:\n",
            "Attempting to create resume PDF at: resume.pdf\n",
            "the directory is \n",
            "SUCCESS: PDF created at resume.pdf\n"
          ]
        }
      ],
      "source": [
        "!python resumy.py build -o resume.pdf output.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "skills= \"\"\"skills:\n",
        "- name: Data Science\n",
        "  keywords: \n",
        "    - SQL\n",
        "    - Predictive Analytics\n",
        "    - Data Engineering\n",
        "    - Data Visualization\n",
        "- name: Programming\n",
        "  keywords: \n",
        "    - Python\n",
        "    - Power Query\n",
        "    - Automation\n",
        "    - Python-based tools\n",
        "- name: Business Intelligence\n",
        "  keywords: \n",
        "    - Tableau\n",
        "    - Power BI\n",
        "    - Data-driven solutions\n",
        "    - Data Visualization\n",
        "- name: Leadership\n",
        "  keywords: \n",
        "    - Leadership skills\n",
        "    - Teamwork\n",
        "    - Communication skills\n",
        "    - Proactive approach\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the new YAML content from the LLM output\n",
        "skill = yaml.safe_load(skills)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ski"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['SQL', 'Predictive Analytics', 'Data Engineering', 'Data Visualization']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skill[\"skills\"][0]['keywords']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "yaml_file_path = r'C:\\Users\\karth\\OneDrive\\Documents\\GitHub\\pdf-build\\karthik.yaml'\n",
        "with open(yaml_file_path, 'r') as f:\n",
        "    resume_data = yaml.safe_load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Prompt Engineering', 'RAG Development', 'LLMs (OpenAI, llama, LangChain)']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resume_data['skills'][0]['keywords']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPCaZx/Db0SJumCv0pb9W3i",
      "include_colab_link": true,
      "mount_file_id": "https://github.com/KarthikeyanBaskaran/pdf-build/blob/main/Resume_Generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
